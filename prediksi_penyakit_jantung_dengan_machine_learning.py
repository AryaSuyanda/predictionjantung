# -*- coding: utf-8 -*-
"""Prediksi Penyakit Jantung dengan Machine Learning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tjXTpdAtxREVDy886vsTlRvDZUQP28fa

# **1. Pendahuluan**

# 💓 Prediksi Penyakit Jantung dengan Machine Learning

Penyakit jantung merupakan salah satu penyebab kematian terbesar di dunia. Deteksi dini terhadap potensi penyakit jantung sangat penting agar tindakan pencegahan dapat segera dilakukan. Dalam proyek ini, kita akan membangun model machine learning untuk memprediksi apakah seseorang berisiko terkena penyakit jantung berdasarkan data klinis mereka.

## 🎯 Tujuan Proyek
Membangun model klasifikasi untuk memprediksi keberadaan penyakit jantung berdasarkan fitur-fitur pasien seperti usia, jenis kelamin, tekanan darah, dan hasil tes laboratorium.

---

# **2. Import Library**
"""

# Manipulasi data
import pandas as pd
import numpy as np

# Visualisasi
import matplotlib.pyplot as plt
import seaborn as sns

# Machine learning
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score, roc_curve
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier

import warnings
warnings.filterwarnings('ignore')

"""# **3. Load Dataset**

## 📂 Load Dataset

Dataset yang digunakan berasal dari Kaggle: [Heart Disease UCI](https://www.kaggle.com/datasets/cherngs/heart-disease-cleveland-uci)
"""

# Gantilah path dengan lokasi file dataset kalian
df = pd.read_csv('/content/Heart_Disease_Prediction.csv')
df.head()

"""# **4. Data Understanding & Exploratory Data Analysis (EDA)**

## 🔍 Data Understanding

Mari kita lihat bentuk umum dataset dan informasi statistik awal.
"""

df.info()
df.describe()
df.isnull().sum()

"""### 🔬 Distribusi Target

"""

# Rename kolom agar konsisten
df.rename(columns={'Heart Disease': 'target'}, inplace=True)

# Cek nilai unik dari target
print(df['target'].unique())

# Mapping target: Presence → 1, Absence → 0
df['target'] = df['target'].map({'Absence': 0, 'Presence': 1})

sns.countplot(x='target', data=df)
plt.title('Distribusi Target (0 = Sehat, 1 = Penyakit Jantung)')
plt.xlabel('Target')
plt.ylabel('Jumlah')
plt.xticks([0, 1], ['Sehat', 'Penyakit Jantung'])
plt.show()

"""### 📈 Korelasi antar fitur

"""

plt.figure(figsize=(12,8))
sns.heatmap(df.corr(), annot=True, cmap='coolwarm')
plt.title('Matriks Korelasi')
plt.show()

"""# **5. Data Preparation**

## 🧼 Data Preparation

Kami akan:
- Memisahkan fitur dan target
- Standarisasi fitur numerik
- Split data ke dalam training dan testing set
"""

X = df.drop('target', axis=1)
y = df['target']

# Standarisasi
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Split
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)

"""# **6. Modeling**

## 🤖 Modeling

Kami akan mencoba tiga model:
1. Logistic Regression
2. Random Forest
3. XGBoost
"""

# Logistic Regression
lr = LogisticRegression()
lr.fit(X_train, y_train)
y_pred_lr = lr.predict(X_test)

# Random Forest
rf = RandomForestClassifier(random_state=42)
rf.fit(X_train, y_train)
y_pred_rf = rf.predict(X_test)

# XGBoost
xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss')
xgb.fit(X_train, y_train)
y_pred_xgb = xgb.predict(X_test)

"""# 7. Evaluation

## 📊 Evaluasi Model

Mari kita bandingkan akurasi dan metrik evaluasi lainnya dari ketiga model.
"""

def evaluate_model(name, y_test, y_pred):
    print(f"📌 {name}")
    print(classification_report(y_test, y_pred))
    print("Confusion Matrix:")
    print(confusion_matrix(y_test, y_pred))
    print('-'*50)

evaluate_model("Logistic Regression", y_test, y_pred_lr)
evaluate_model("Random Forest", y_test, y_pred_rf)
evaluate_model("XGBoost", y_test, y_pred_xgb)

"""# **8. Model Comparison & Final Model**

## 🏁 Model Terbaik

Berdasarkan evaluasi di atas, kita dapat memilih model dengan performa terbaik. Jika selisih akurasi sangat kecil, kita bisa memilih model yang lebih sederhana untuk deployment (seperti Logistic Regression).

Tambahkan juga ROC Curve untuk membandingkan model secara visual.

# **9. ROC Curve**
"""

models = {
    'Logistic Regression': lr,
    'Random Forest': rf,
    'XGBoost': xgb
}

plt.figure(figsize=(10, 6))

for name, model in models.items():
    y_probs = model.predict_proba(X_test)[:, 1]
    fpr, tpr, _ = roc_curve(y_test, y_probs)
    auc_score = roc_auc_score(y_test, y_probs)
    plt.plot(fpr, tpr, label=f'{name} (AUC = {auc_score:.2f})')

plt.plot([0, 1], [0, 1], 'k--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve Comparison')
plt.legend()
plt.grid(True)
plt.show()

"""# 10. Kesimpulan

## ✅ Kesimpulan

📌 Final Decision:
Model terbaik berdasarkan evaluasi kuantitatif (akurasi dan f1-score) adalah **Logistic Regression** dengan akurasi 85%. Selain itu, model ini juga lebih sederhana dan lebih mudah digunakan untuk deployment pada aplikasi real-time seperti sistem deteksi dini penyakit jantung.

📌 Catatan:
Random Forest dan XGBoost memiliki performa yang sebanding, namun kompleksitasnya lebih tinggi dibanding Logistic Regression.
"""